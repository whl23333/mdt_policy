_target_: pytorch_lightning.callbacks.ModelCheckpoint
# Save from the start of training, every 2 epochs, on train epoch end
save_top_k: -1               # save all checkpoints at the given frequency
verbose: True
dirpath: saved_models
filename: '{epoch:02d}'
every_n_epochs: 1
save_on_train_epoch_end: true
# No validation metric needed; we disable monitor so saving is not tied to evaluation
# monitor: null
